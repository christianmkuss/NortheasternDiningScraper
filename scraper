from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


def levine_marketplace():
    url = "https://new.dineoncampus.com/Northeastern/menus"
    browser = webdriver.PhantomJS("C:\\Users\chris\Documents\phantomjs-2.1.1-windows\\bin\phantomjs.exe")
    browser.get(url)
    WebDriverWait(browser, 10).until(
        EC.presence_of_element_located((By.CLASS_NAME, "item-row"))
    )
    html = browser.page_source
    soup = BeautifulSoup(html, "html.parser")
    breakfast = soup.findAll("td", {"class": "item-name"})
    # for item in breakfast:
    #     print(item.strong.find(text=True, recursive=False).strip())
    browser.find_element_by_xpath('//a[.="Lunch"]').click()
    lunchhtml = browser.page_source
    lunchsoup = BeautifulSoup(lunchhtml, "html.parser")
    lunch = lunchsoup.findAll("td", {"class": "item-name"})
    # for item in lunch:
    #     print(item.strong.find(text=True, recursive=False).strip())
    browser.find_element_by_xpath('//a[.="Dinner"]').click()
    dinnerhtml = browser.page_source
    browser.close()
    dinnersoup = BeautifulSoup(dinnerhtml, "html.parser")
    dinner = dinnersoup.findAll("td", {"class": "item-name"})
    for item in dinner:
        print(item.strong.find(text=True, recursive=False).strip())


def internation_village():
    url = "https://new.dineoncampus.com/Northeastern/menus"
    browser = webdriver.PhantomJS("C:\\Users\chris\Documents\phantomjs-2.1.1-windows\\bin\phantomjs.exe")
    browser.get(url)
    WebDriverWait(browser, 10).until(
        EC.presence_of_element_located((By.CLASS_NAME, "item-row"))
    )
    browser.find_element_by_xpath('//span[.="Levine Marketplace"]').click()
    browser.find_element_by_xpath('//div[.="International Village"]').click()
    WebDriverWait(browser, 10).until(
        EC.presence_of_element_located((By.CLASS_NAME, "item-row"))
    )
    html = browser.page_source
    soup = BeautifulSoup(html, "html.parser")
    breakfast = soup.findAll("td", {"class": "item-name"})
    # for item in breakfast:
    #     print(item.strong.find(text=True, recursive=False).strip())
    browser.find_element_by_xpath('//a[.="Lunch"]').click()
    lunchhtml = browser.page_source
    lunchsoup = BeautifulSoup(lunchhtml, "html.parser")
    lunch = lunchsoup.findAll("td", {"class": "item-name"})
    # for item in lunch:
    #     print(item.strong.find(text=True, recursive=False).strip())
    browser.find_element_by_xpath('//a[.="Dinner"]').click()
    dinnerhtml = browser.page_source
    browser.close()
    dinnersoup = BeautifulSoup(dinnerhtml, "html.parser")
    dinner = dinnersoup.findAll("td", {"class": "item-name"})
    for item in dinner:
        print(item.strong.find(text=True, recursive=False).strip())


if __name__ == '__main__':
    internation_village()

